{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a.block/Library/Python/3.8/lib/python/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from Datasets import get_loaders\n",
    "from Augmentations import augment\n",
    "from MoCoTrainer import get_MoCo_feature_extractor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Hyperparams taken from paper\n",
    "TEMPERATURE = 0.07\n",
    "MOMENTUM = 0.999\n",
    "KEY_DICTIONARY_SIZE = 4096\n",
    "NUM_EPOCHS = 800"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def accuracy(predicted_labels, true_labels):\n",
    "    return (predicted_labels == true_labels).sum() / len(true_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "' First test MoCoTrainer.py successful train (incomplete), then test quality of extracted features with this classifier\\nclass Classifier(torch.nn.Module):\\n    def __init__(self, feature_extractor: torch.nn.Module, loss_func, optimizer_type):\\n        device = \\'cuda\\' if torch.cuda.is_available() else \\'cpu\\'\\n        self.feature_extractor = feature_extractor.to(device=device)\\n        ftr_exctr_final_layer = self.feature_extractor.fc[-1]\\n        self.fc = torch.nn.Linear(in_features=ftr_exctr_final_layer.out_features, out_features=ftr_exctr_final_layer.out_features, device=device)\\n        self.loss_func = loss_func\\n        self.optimizer = optimizer_type(self.fc.parameters())\\n\\n    def forward(self, x):\\n        with torch.no_grad():\\n            x = self.feature_extractor(x)  # Only fine-tune classifier head\\n        x = self.fc(x)\\n        return x\\n\\n    def train(self, train_loader, val_loader=None):\\n        validation_accuracies = []\\n        for _ in tqdm(range(NUM_EPOCHS)):\\n            for inputs, true_labels in train_loader:\\n                self.optimizer.zero_grad()\\n\\n                predicted_labels = self.forward(inputs)\\n                loss = self.loss_func(predicted_labels, true_labels)\\n                loss.backward()\\n                self.optimizer.step()\\n\\n                print(f\"loss={loss}\")\\n\\n                if val_loader:\\n                    inputs, true_labels = next(val_loader)\\n                    with torch.no_grad():\\n                        predicted_labels = self.forward(inputs)\\n                    validation_accuracies.append(accuracy(predicted_labels=predicted_labels, true_labels=true_labels))\\n\\n    def test(self, test_loader):\\n        total_correct = 0\\n        test_size = 0\\n        for inputs, true_labels in test_loader:\\n            predicted_labels = self.forward(inputs)\\n            total_correct += (predicted_labels == true_labels).sum()\\n            test_size += len(true_labels)\\n\\n        print(f\"Accuracy: {total_correct / test_size}\")\\n'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' First test MoCoTrainer.py successful train (incomplete), then test quality of extracted features with this classifier\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, feature_extractor: torch.nn.Module, loss_func, optimizer_type):\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.feature_extractor = feature_extractor.to(device=device)\n",
    "        ftr_exctr_final_layer = self.feature_extractor.fc[-1]\n",
    "        self.fc = torch.nn.Linear(in_features=ftr_exctr_final_layer.out_features, out_features=ftr_exctr_final_layer.out_features, device=device)\n",
    "        self.loss_func = loss_func\n",
    "        self.optimizer = optimizer_type(self.fc.parameters())\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)  # Only fine-tune classifier head\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def train(self, train_loader, val_loader=None):\n",
    "        validation_accuracies = []\n",
    "        for _ in tqdm(range(NUM_EPOCHS)):\n",
    "            for inputs, true_labels in train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                predicted_labels = self.forward(inputs)\n",
    "                loss = self.loss_func(predicted_labels, true_labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                print(f\"loss={loss}\")\n",
    "\n",
    "                if val_loader:\n",
    "                    inputs, true_labels = next(val_loader)\n",
    "                    with torch.no_grad():\n",
    "                        predicted_labels = self.forward(inputs)\n",
    "                    validation_accuracies.append(accuracy(predicted_labels=predicted_labels, true_labels=true_labels))\n",
    "\n",
    "    def test(self, test_loader):\n",
    "        total_correct = 0\n",
    "        test_size = 0\n",
    "        for inputs, true_labels in test_loader:\n",
    "            predicted_labels = self.forward(inputs)\n",
    "            total_correct += (predicted_labels == true_labels).sum()\n",
    "            test_size += len(true_labels)\n",
    "\n",
    "        print(f\"Accuracy: {total_correct / test_size}\")\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mInitializing feature extractor training\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/a.block/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mGenerating initial keys queue\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/a.block/Library/Python/3.8/lib/python/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/a.block/Library/Python/3.8/lib/python/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/Users/a.block/Library/Python/3.8/lib/python/site-packages/torch/utils/data/_utils/collate.py\", line 84, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/Users/a.block/Library/Python/3.8/lib/python/site-packages/torch/utils/data/_utils/collate.py\", line 84, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/Users/a.block/Library/Python/3.8/lib/python/site-packages/torch/utils/data/_utils/collate.py\", line 56, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 375, 500] at entry 0 and [3, 399, 500] at entry 8\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/5x/m7lb9lzs49170h6y7nsh5jq80000gp/T/ipykernel_87847/3150167470.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_loader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_loaders\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"imagenette2\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m256\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mget_MoCo_feature_extractor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtemperature\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mTEMPERATURE\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloader\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maugment\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maugment\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmomentum\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mMOMENTUM\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey_dictionary_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mKEY_DICTIONARY_SIZE\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mNUM_EPOCHS\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/MoCo/MoCoTrainer.py\u001B[0m in \u001B[0;36mget_MoCo_feature_extractor\u001B[0;34m(temperature, loader, augment, momentum, key_dictionary_size, num_epochs)\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0mnum_initial_key_batches\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkey_dictionary_size\u001B[0m \u001B[0;34m//\u001B[0m \u001B[0mloader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0mloader_iterator\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDataLoaderCyclicIterator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m     keys_queue = torch.stack([\n\u001B[0m\u001B[1;32m     55\u001B[0m         f_k(\n\u001B[1;32m     56\u001B[0m             \u001B[0maugment\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloader_iterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/MoCo/MoCoTrainer.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     54\u001B[0m     keys_queue = torch.stack([\n\u001B[1;32m     55\u001B[0m         f_k(\n\u001B[0;32m---> 56\u001B[0;31m             \u001B[0maugment\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloader_iterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     57\u001B[0m         )\n\u001B[1;32m     58\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_initial_key_batches\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/MoCo/DataHandling.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__next__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miterator\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0miter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataloader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    519\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    520\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 521\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    522\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    523\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1201\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1202\u001B[0m                 \u001B[0;32mdel\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_task_info\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1203\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_process_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1204\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1205\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_try_put_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_process_data\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1227\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_try_put_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1228\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mExceptionWrapper\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1229\u001B[0;31m             \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreraise\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1230\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1231\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/_utils.py\u001B[0m in \u001B[0;36mreraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    432\u001B[0m             \u001B[0;31m# instantiate since we don't know how to\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    433\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 434\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mexception\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    435\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    436\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/a.block/Library/Python/3.8/lib/python/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/a.block/Library/Python/3.8/lib/python/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/Users/a.block/Library/Python/3.8/lib/python/site-packages/torch/utils/data/_utils/collate.py\", line 84, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/Users/a.block/Library/Python/3.8/lib/python/site-packages/torch/utils/data/_utils/collate.py\", line 84, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/Users/a.block/Library/Python/3.8/lib/python/site-packages/torch/utils/data/_utils/collate.py\", line 56, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 375, 500] at entry 0 and [3, 399, 500] at entry 8\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_loaders(data_path=\"imagenette2\", batch_size=256)\n",
    "get_MoCo_feature_extractor(temperature=TEMPERATURE, loader=train_loader, augment=augment, momentum=MOMENTUM, key_dictionary_size=KEY_DICTIONARY_SIZE, num_epochs=NUM_EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}